{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13611596,"sourceType":"datasetVersion","datasetId":8650079}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport joblib\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# ===============================\n# LOAD ALIGNED NB15 DATA\n# ===============================\ntrain = pd.read_csv(\"/kaggle/input/cicds-unsw-alligned-dataset/UNSW_aligned_train.csv\")\ntest = pd.read_csv(\"/kaggle/input/cicds-unsw-alligned-dataset/UNSW_aligned_test.csv\")\n\nprint(\"Train:\", train.shape, \" | Test:\", test.shape)\n\n# ===============================\n# Ensure attack_cat exists\n# ===============================\ntrain[\"attack_cat\"] = pd.to_numeric(train[\"attack_cat\"], errors=\"coerce\")\ntest[\"attack_cat\"] = pd.to_numeric(test[\"attack_cat\"], errors=\"coerce\")\ntrain.dropna(subset=[\"attack_cat\"], inplace=True)\ntest.dropna(subset=[\"attack_cat\"], inplace=True)\ntrain[\"attack_cat\"] = train[\"attack_cat\"].astype(int)\ntest[\"attack_cat\"] = test[\"attack_cat\"].astype(int)\n\nprint(\"Label distribution (train):\", Counter(train[\"attack_cat\"]))\n\n# ===============================\n# OPTIONAL: BALANCE Dataset\n# ===============================\n# Drop to max 80k per class (safe for 16GB RAM)\nmax_samples = 80000\nbalanced_train = train.groupby(\"attack_cat\", group_keys=False).apply(lambda x: x.sample(min(len(x), max_samples), random_state=42))\nbalanced_test  = test.groupby(\"attack_cat\", group_keys=False).apply(lambda x: x.sample(min(len(x), max_samples), random_state=42))\n\nprint(\"Balanced train:\", balanced_train.shape, \" | Balanced test:\", balanced_test.shape)\n\nX_train = balanced_train.drop(columns=[\"attack_cat\"])\ny_train = balanced_train[\"attack_cat\"]\n\nX_test = balanced_test.drop(columns=[\"attack_cat\"])\ny_test = balanced_test[\"attack_cat\"]\n\n# ===============================\n# SCALING\n# ===============================\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\njoblib.dump(scaler, \"nb15_aligned_scaler.pkl\")\n\n# ===============================\n# CLASS WEIGHTS\n# ===============================\nclasses = np.unique(y_train)\ncw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\nclass_weights = {classes[i]: float(cw[i]) for i in range(len(cw))}\nprint(\"Class Weights:\", class_weights)\n\n# ===============================\n# MODELS\n# ===============================\nmodel_lgb = LGBMClassifier(\n    n_estimators=300,\n    learning_rate=0.05,\n    num_leaves=31,\n    subsample=0.7,\n    colsample_bytree=0.7,\n    class_weight=class_weights,\n    random_state=42,\n    n_jobs=-1\n)\n\nmodel_xgb = XGBClassifier(\n    objective=\"multi:softprob\",\n    num_class=len(classes),\n    tree_method=\"hist\",\n    n_estimators=300,\n    max_depth=8,\n    learning_rate=0.05,\n    subsample=0.7,\n    colsample_bytree=0.7,\n    eval_metric=\"mlogloss\",\n    random_state=42\n)\n\nmodel_cat = CatBoostClassifier(\n    iterations=300,\n    learning_rate=0.05,\n    depth=6,\n    class_weights=list(cw),\n    verbose=False\n)\n\nmodel_rf = RandomForestClassifier(\n    n_estimators=200,\n    max_depth=14,\n    class_weight=\"balanced\",\n    random_state=42,\n    n_jobs=-1\n)\n\n# ===============================\n# TRAIN\n# ===============================\nprint(\"\\nTraining models...\")\nmodel_lgb.fit(X_train, y_train)\nmodel_xgb.fit(X_train, y_train)\nmodel_cat.fit(X_train, y_train)\nmodel_rf.fit(X_train, y_train)\n\njoblib.dump(model_lgb, \"nb15_lgb.pkl\")\njoblib.dump(model_xgb, \"nb15_xgb.pkl\")\njoblib.dump(model_cat, \"nb15_cat.pkl\")\njoblib.dump(model_rf, \"nb15_rf.pkl\")\n\nprint(\"✅ Models saved!\")\n\n# ===============================\n# ENSEMBLE TESTING\n# ===============================\np1 = model_lgb.predict_proba(X_test)\np2 = model_xgb.predict_proba(X_test)\np3 = model_cat.predict_proba(X_test)\np4 = model_rf.predict_proba(X_test)\n\np_ens = (p1 + p2 + p3 + p4) / 4.0\ny_pred = np.argmax(p_ens, axis=1)\n\nprint(\"\\n✅ NB15 Ensemble Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"✅ NB15 Macro F1:\", f1_score(y_test, y_pred, average=\"macro\"))\nprint(classification_report(y_test, y_pred, zero_division=0))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:24:04.987808Z","iopub.execute_input":"2025-11-04T17:24:04.988198Z","iopub.status.idle":"2025-11-04T17:27:02.680122Z","shell.execute_reply.started":"2025-11-04T17:24:04.988176Z","shell.execute_reply":"2025-11-04T17:27:02.678928Z"}},"outputs":[{"name":"stdout","text":"Train: (82332, 133)  | Test: (175341, 133)\nLabel distribution (train): Counter({6: 37000, 5: 18871, 3: 11132, 4: 6062, 2: 4089, 7: 3496, 0: 677, 1: 583, 8: 378, 9: 44})\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_37/3673682627.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  balanced_train = train.groupby(\"attack_cat\", group_keys=False).apply(lambda x: x.sample(min(len(x), max_samples), random_state=42))\n/tmp/ipykernel_37/3673682627.py:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  balanced_test  = test.groupby(\"attack_cat\", group_keys=False).apply(lambda x: x.sample(min(len(x), max_samples), random_state=42))\n","output_type":"stream"},{"name":"stdout","text":"Balanced train: (82332, 133)  | Balanced test: (175341, 133)\nClass Weights: {0: 12.161299852289513, 1: 14.1221269296741, 2: 2.013499633162142, 3: 0.739597556593604, 4: 1.3581656219069613, 5: 0.4362884849769488, 6: 0.22251891891891892, 7: 2.3550343249427916, 8: 21.78095238095238, 9: 187.11818181818182}\n\nTraining models...\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010770 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 8520\n[LightGBM] [Info] Number of data points in the train set: 82332, number of used features: 53\n[LightGBM] [Info] Start training from score -2.302585\n[LightGBM] [Info] Start training from score -2.302585\n[LightGBM] [Info] Start training from score -2.302585\n[LightGBM] [Info] Start training from score -2.302585\n[LightGBM] [Info] Start training from score -2.302585\n[LightGBM] [Info] Start training from score -2.302585\n[LightGBM] [Info] Start training from score -2.302585\n[LightGBM] [Info] Start training from score -2.302585\n[LightGBM] [Info] Start training from score -2.302585\n[LightGBM] [Info] Start training from score -2.302585\n✅ Models saved!\n\n✅ NB15 Ensemble Accuracy: 0.7691241637723065\n✅ NB15 Macro F1: 0.5718597679668158\n              precision    recall  f1-score   support\n\n           0       0.05      0.03      0.04      2000\n           1       0.28      0.10      0.14      1746\n           2       0.34      0.76      0.47     12264\n           3       0.85      0.54      0.66     33393\n           4       0.73      0.24      0.36     18184\n           5       0.99      0.98      0.99     40000\n           6       0.80      0.97      0.88     56000\n           7       0.87      0.79      0.83     10491\n           8       0.59      0.78      0.67      1133\n           9       0.65      0.73      0.69       130\n\n    accuracy                           0.77    175341\n   macro avg       0.61      0.59      0.57    175341\nweighted avg       0.80      0.77      0.76    175341\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nprobs = p_ens  # ensemble probabilities\nthresholds = []\nfor c in range(probs.shape[1]):\n    cls_mean = np.mean(probs[y_test == c][:, c])\n    thresholds.append(cls_mean * 0.8)\n\nthresholds = np.array(thresholds)\n\nadjusted_pred = []\nfor i in range(len(probs)):\n    scaled = probs[i] / thresholds\n    adjusted_pred.append(np.argmax(scaled))\nadjusted_pred = np.array(adjusted_pred)\n\nprint(\"Tuned Accuracy:\", accuracy_score(y_test, adjusted_pred))\nprint(\"Tuned Macro F1:\", f1_score(y_test, adjusted_pred, average=\"macro\"))\nprint(classification_report(y_test, adjusted_pred, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T17:29:48.474597Z","iopub.execute_input":"2025-11-04T17:29:48.474990Z","iopub.status.idle":"2025-11-04T17:29:49.047377Z","shell.execute_reply.started":"2025-11-04T17:29:48.474966Z","shell.execute_reply":"2025-11-04T17:29:49.046150Z"}},"outputs":[{"name":"stdout","text":"Tuned Accuracy: 0.7528473089579734\nTuned Macro F1: 0.5865543563200181\n              precision    recall  f1-score   support\n\n           0       0.05      0.38      0.09      2000\n           1       0.11      0.16      0.13      1746\n           2       0.35      0.38      0.36     12264\n           3       0.86      0.53      0.65     33393\n           4       0.64      0.52      0.58     18184\n           5       1.00      0.98      0.99     40000\n           6       0.87      0.91      0.89     56000\n           7       0.90      0.76      0.83     10491\n           8       0.59      0.78      0.67      1133\n           9       0.66      0.71      0.68       130\n\n    accuracy                           0.75    175341\n   macro avg       0.60      0.61      0.59    175341\nweighted avg       0.82      0.75      0.78    175341\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}